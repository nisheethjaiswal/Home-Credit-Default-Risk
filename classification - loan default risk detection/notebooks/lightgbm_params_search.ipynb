{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turned-commons",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:46.353810Z",
     "start_time": "2021-05-12T19:42:40.195569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "N_FOLDS = 5\n",
    "MAX_EVALS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infinite-modem",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:46.369838Z",
     "start_time": "2021-05-12T19:42:46.353810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-bikini",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-suite",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is extremely computationally expensive and working with the full dataset, so we only try on small subset and use the best hyperparamaters to train the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outdoor-finish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:48.609918Z",
     "start_time": "2021-05-12T19:42:46.369838Z"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/application_train.csv')\n",
    "\n",
    "# Sample 16000 rows (10000 for training, 6000 for testing)\n",
    "features = features.sample(n = 16000, random_state = 42)\n",
    "\n",
    "# Only numeric features\n",
    "features = features.select_dtypes('number')\n",
    "\n",
    "# Extract the labels (lgb takes in array)\n",
    "labels = np.array(features['TARGET'].astype(np.int32)).reshape((-1, ))\n",
    "features = features.drop(columns = ['TARGET', 'SK_ID_CURR'])\n",
    "\n",
    "# Split into training and testing data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 6000, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "adolescent-racing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T20:31:59.086020Z",
     "start_time": "2021-05-12T20:31:59.077044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chief-antibody",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:48.641912Z",
     "start_time": "2021-05-12T19:42:48.613925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-syndrome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T03:20:05.911498Z",
     "start_time": "2021-05-12T03:20:05.583937Z"
    }
   },
   "source": [
    "We will also use only the numeric features to reduce the number of dimensions which will help speed up the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imposed-wheel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:48.657881Z",
     "start_time": "2021-05-12T19:42:48.641912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape:  (10000, 104)\n",
      "Testing features shape:  (6000, 104)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training features shape: \", train_features.shape)\n",
    "print(\"Testing features shape: \", test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-equality",
   "metadata": {},
   "source": [
    "**Cross Validation** <br/>\n",
    "To use the `cv` fct, we first need to make a LightGBM `dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contrary-graphic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:48.673880Z",
     "start_time": "2021-05-12T19:42:48.657881Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = lgb.Dataset(data = train_features, label = train_labels, free_raw_data=False)\n",
    "test_set = lgb.Dataset(data = test_features, label = test_labels, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "infectious-lyric",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:48.686445Z",
     "start_time": "2021-05-12T19:42:48.673880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lightgbm.basic.Dataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-edgar",
   "metadata": {},
   "source": [
    "`num_boost_round` is the same as `n_estimators` and is set to 10000 (we use early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cooperative-kingdom",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:48.702444Z",
     "start_time": "2021-05-12T19:42:48.686445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "default_params = model.get_params()\n",
    "default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minus-finder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:48.718791Z",
     "start_time": "2021-05-12T19:42:48.702444Z"
    }
   },
   "outputs": [],
   "source": [
    "#Remove the n_estimators\n",
    "del default_params['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "noted-gravity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:50.217388Z",
     "start_time": "2021-05-12T19:42:48.718791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tqluo\\Anaconda3\\envs\\metis\\lib\\site-packages\\lightgbm\\basic.py:1222: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Info] Start training from score 0.081625\n"
     ]
    }
   ],
   "source": [
    "#Cross val with early stopping\n",
    "cv_results = lgb.cv(default_params, train_set, \n",
    "                    num_boost_round=10000, early_stopping_rounds=100, metrics='auc', nfold = N_FOLDS, seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "magnetic-pressure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:50.229389Z",
     "start_time": "2021-05-12T19:42:50.217388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum validation ROC AUC was: 0.71172 with a standard deviation of 0.02089.\n",
      "The optimal number of boosting rounds (estimators) was 28.\n"
     ]
    }
   ],
   "source": [
    "print('The maximum validation ROC AUC was: {:.5f} with a standard deviation of {:.5f}.'.format(cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\n",
    "print('The optimal number of boosting rounds (estimators) was {}.'.format(len(cv_results['auc-mean'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-concentrate",
   "metadata": {},
   "source": [
    "We can use this result as a baseline model to beat. To find out how well the model does on our \"test\" data, we will retrain it on all the training data with the best number of estimators found during cross validation with early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "departmental-strengthening",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:50.245388Z",
     "start_time": "2021-05-12T19:42:50.229389Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "geographic-elder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:50.261389Z",
     "start_time": "2021-05-12T19:42:50.245388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimal number of estimators found in cv\n",
    "model.n_estimators = len(cv_results['auc-mean'])\n",
    "model.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "heard-yukon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:50.409388Z",
     "start_time": "2021-05-12T19:42:50.261389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set:  0.7215389632973158\n"
     ]
    }
   ],
   "source": [
    "#Train and make predictions on test set\n",
    "model.fit(train_features, train_labels)\n",
    "preds = model.predict_proba(test_features)[:, 1]\n",
    "baseline_auc = roc_auc_score(test_labels, preds)\n",
    "\n",
    "print('ROC AUC on test set: ', baseline_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-return",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-permit",
   "metadata": {},
   "source": [
    "This is the baseline score before hyperparameter tuning. The only difference we made from the default model was using early stopping to set the number of estimators (which by default is 100)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-belle",
   "metadata": {},
   "source": [
    "#### Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-aviation",
   "metadata": {},
   "source": [
    "The objective function takes in hyperparameters and outputs a value representing a score. Traditionally in optimization, this is a score to minimize, but here our score will be the ROC AUC which of course we want to maximize. Later, when we get to Bayesian Optimization, we will have to use a value to minimize, so we can take  **1−ROC AUC**  as the score. What occurs in the middle of the objective function will vary according to the problem, but for this problem, we will use cross validation with the specified model hyperparameters to get the cross-validation ROC AUC. This score will then be used to select the best model hyperparameter values.\n",
    "<br/>\n",
    "In addition to returning the value to maximize, our objective function will return the hyperparameters and the iteration of the search. These results will let us go back and inspect what occurred during a search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "instructional-habitat",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:50.425388Z",
     "start_time": "2021-05-12T19:42:50.409388Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(hyperparameters, iteration):\n",
    "    \"\"\"Objective function for grid and random search. Returns\n",
    "       the cross validation score from a set of hyperparameters.\"\"\"\n",
    "    \n",
    "    # Number of estimators will be found using early stopping\n",
    "    if 'n_estimators' in hyperparameters.keys():\n",
    "        del hyperparameters['n_estimators']\n",
    "    \n",
    "     # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 42)\n",
    "    \n",
    "    # results to retun\n",
    "    score = cv_results['auc-mean'][-1]\n",
    "    estimators = len(cv_results['auc-mean'])\n",
    "    hyperparameters['n_estimators'] = estimators \n",
    "    \n",
    "    return [score, hyperparameters, iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "processed-dryer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:51.677386Z",
     "start_time": "2021-05-12T19:42:50.425388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "The cross-validation ROC AUC was 0.69849.\n"
     ]
    }
   ],
   "source": [
    "score, params, iteration = objective(default_params, 1)\n",
    "\n",
    "print('The cross-validation ROC AUC was {:.5f}.'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-campaign",
   "metadata": {},
   "source": [
    "#### Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "parental-yukon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:51.693386Z",
     "start_time": "2021-05-12T19:42:51.677386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': True,\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a default model\n",
    "model = lgb.LGBMModel()\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-north",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "vanilla-english",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:51.709386Z",
     "start_time": "2021-05-12T19:42:51.693386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(20, 150)),\n",
    "    'learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.5), base = 10, num = 1000)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10)),\n",
    "    'subsample': list(np.linspace(0.5, 1, 100)),\n",
    "    'is_unbalance': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-italic",
   "metadata": {},
   "source": [
    "One aspect to note is that if boosting_type is goss, then we cannot use subsample (which refers to training on only a fraction of the rows in the training data, a technique known as stochastic gradient boosting). Therefore, we will need a line of logic in our algorithm that sets the subsample to 1.0 (which means use all the rows) if boosting_type=goss. As an example below, if we randomly select a set of hyperparameters, and the boosting type is \"goss\", then we set the subsample to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sound-rhythm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:51.725387Z",
     "start_time": "2021-05-12T19:42:51.709386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting type:  goss\n",
      "Subsample ratio:  1.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(50)\n",
    "\n",
    "# Randomly sample a boosting type\n",
    "boosting_type = random.sample(param_grid['boosting_type'], 1)[0]\n",
    "\n",
    "# Set subsample depending on boosting type\n",
    "subsample = 1.0 if boosting_type == 'goss' else random.sample(param_grid['subsample'], 1)[0]\n",
    "\n",
    "print('Boosting type: ', boosting_type)\n",
    "print('Subsample ratio: ', subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "norman-stanley",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:52.373618Z",
     "start_time": "2021-05-12T19:42:51.725387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Learning rate histogram\n",
    "plt.hist(param_grid['learning_rate'], bins = 20, color = 'r', edgecolor = 'k');\n",
    "plt.xlabel('Learning Rate', size = 14); plt.ylabel('Count', size = 14); plt.title('Learning Rate Distribution', size = 18);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-finnish",
   "metadata": {},
   "source": [
    "#### Results history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "typical-profit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:52.385613Z",
     "start_time": "2021-05-12T19:42:52.373618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataframes for random and grid search\n",
    "random_results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                              index = list(range(MAX_EVALS)))\n",
    "\n",
    "grid_results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                              index = list(range(MAX_EVALS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "theoretical-serial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:42:52.397614Z",
     "start_time": "2021-05-12T19:42:52.385613Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def grid_search(param_grid, max_evals = MAX_EVALS):\n",
    "    \"\"\"Grid search algorithm (with limit on max evals)\"\"\"\n",
    "    \n",
    "    # Dataframe to store results\n",
    "    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                              index = list(range(MAX_EVALS)))\n",
    "    \n",
    "    # https://codereview.stackexchange.com/questions/171173/list-all-possible-permutations-from-a-python-dictionary-of-lists\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    # Iterate through every possible combination of hyperparameters\n",
    "    for v in itertools.product(*values):\n",
    "        \n",
    "        # Create a hyperparameter dictionary\n",
    "        hyperparameters = dict(zip(keys, v))\n",
    "        \n",
    "        # Set the subsample ratio accounting for boosting type\n",
    "        hyperparameters['subsample'] = 1.0 if hyperparameters['boosting_type'] == 'goss' else hyperparameters['subsample']\n",
    "        \n",
    "        # Evalute the hyperparameters\n",
    "        eval_results = objective(hyperparameters, i)\n",
    "        \n",
    "        results.loc[i, :] = eval_results\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        # Normally would not limit iterations\n",
    "        if i > MAX_EVALS:\n",
    "            break\n",
    "       \n",
    "    # Sort with best score on top\n",
    "    results.sort_values('score', ascending = False, inplace = True)\n",
    "    results.reset_index(inplace = True)\n",
    "    \n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rocky-legend",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:43:26.168503Z",
     "start_time": "2021-05-12T19:42:52.401615Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Info] Start training from score 0.081625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tqluo\\Anaconda3\\envs\\metis\\lib\\site-packages\\lightgbm\\basic.py:1222: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  _log_warning('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Info] Start training from score 0.081625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9993\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 93\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081750\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "[LightGBM] [Info] Start training from score 0.081625\n",
      "The best validation score was 0.72024\n",
      "\n",
      "The best hyperparameters were:\n",
      "{'boosting_type': 'gbdt',\n",
      " 'colsample_bytree': 0.6,\n",
      " 'is_unbalance': True,\n",
      " 'learning_rate': 0.004999999999999999,\n",
      " 'min_child_samples': 20,\n",
      " 'n_estimators': 629,\n",
      " 'num_leaves': 20,\n",
      " 'reg_alpha': 0.0,\n",
      " 'reg_lambda': 0.0,\n",
      " 'subsample': 0.5,\n",
      " 'subsample_for_bin': 20000}\n"
     ]
    }
   ],
   "source": [
    "grid_results = grid_search(param_grid)\n",
    "\n",
    "print('The best validation score was {:.5f}'.format(grid_results.loc[0, 'score']))\n",
    "print('\\nThe best hyperparameters were:')\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(grid_results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "injured-edgar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:43:27.192502Z",
     "start_time": "2021-05-12T19:43:26.168503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model from grid search scores 0.73319 ROC AUC on the test set.\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters\n",
    "grid_search_params = grid_results.loc[0, 'params']\n",
    "\n",
    "# Create, train, test model\n",
    "model = lgb.LGBMClassifier(**grid_search_params, random_state=42)\n",
    "model.fit(train_features, train_labels)\n",
    "\n",
    "preds = model.predict_proba(test_features)[:, 1]\n",
    "\n",
    "print('The best model from grid search scores {:.5f} ROC AUC on the test set.'.format(roc_auc_score(test_labels, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fifth-kinase",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:43:27.208502Z",
     "start_time": "2021-05-12T19:43:27.192502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.5, 'is_unbalance': True, 'n_estimators': 629},\n",
       "       {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.5, 'is_unbalance': False, 'n_estimators': 629},\n",
       "       {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.5050505050505051, 'is_unbalance': True, 'n_estimators': 629},\n",
       "       {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.5050505050505051, 'is_unbalance': False, 'n_estimators': 629},\n",
       "       {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.51010101010101, 'is_unbalance': True, 'n_estimators': 629},\n",
       "       {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.51010101010101, 'is_unbalance': False, 'n_estimators': 629}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "grid_results['params'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-rebel",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-warehouse",
   "metadata": {},
   "source": [
    "Random search is surprisingly efficient compared to grid search. Although grid search will find the optimal value of hyperparameters (assuming they are in your grid) eventually, random search will usually find a \"close-enough\" value in far fewer iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faced-counter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:43:27.224501Z",
     "start_time": "2021-05-12T19:43:27.208502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss',\n",
       " 'num_leaves': 88,\n",
       " 'learning_rate': 0.027778881111994384,\n",
       " 'subsample_for_bin': 220000,\n",
       " 'min_child_samples': 175,\n",
       " 'reg_alpha': 0.8979591836734693,\n",
       " 'reg_lambda': 0.6122448979591836,\n",
       " 'colsample_bytree': 0.8222222222222222,\n",
       " 'subsample': 1.0,\n",
       " 'is_unbalance': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(50)\n",
    "\n",
    "# Randomly sample from dictionary\n",
    "random_params = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "# Deal with subsample ratio\n",
    "random_params['subsample'] = 1.0 if random_params['boosting_type'] == 'goss' else random_params['subsample']\n",
    "\n",
    "random_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-incident",
   "metadata": {},
   "source": [
    "Next, we define the `random_search` function. This takes the same general structure as grid_search except for the method used to select the next hyperparameter values. Moreover, random search is always run with a limit on the number of search iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "handed-spirituality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:43:27.236503Z",
     "start_time": "2021-05-12T19:43:27.228502Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_search(param_grid, max_evals = MAX_EVALS):\n",
    "    \"\"\"Random search for hyperparameter optimization\"\"\"\n",
    "    \n",
    "    # Dataframe for results\n",
    "    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                                  index = list(range(MAX_EVALS)))\n",
    "    \n",
    "    # Keep searching until reach max evaluations\n",
    "    for i in range(MAX_EVALS):\n",
    "        \n",
    "        # Choose random hyperparameters\n",
    "        hyperparameters = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "        hyperparameters['subsample'] = 1.0 if hyperparameters['boosting_type'] == 'goss' else hyperparameters['subsample']\n",
    "\n",
    "        # Evaluate randomly selected hyperparameters\n",
    "        eval_results = objective(hyperparameters, i)\n",
    "        \n",
    "        results.loc[i, :] = eval_results\n",
    "    \n",
    "    # Sort with best score on top\n",
    "    results.sort_values('score', ascending = False, inplace = True)\n",
    "    results.reset_index(inplace = True)\n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dimensional-century",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:43:27.252502Z",
     "start_time": "2021-05-12T19:43:27.236503Z"
    }
   },
   "outputs": [],
   "source": [
    "# #This block tooks 15mins\n",
    "\n",
    "# random_results = random_search(param_grid)\n",
    "\n",
    "# print('The best validation score was {:.5f}'.format(random_results.loc[0, 'score']))\n",
    "# print('\\nThe best hyperparameters were:')\n",
    "\n",
    "# import pprint\n",
    "# pprint.pprint(random_results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "realistic-auditor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:44:12.041424Z",
     "start_time": "2021-05-12T19:44:12.029424Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Get the best parameters\n",
    "# random_search_params = random_results.loc[0, 'params']\n",
    "\n",
    "# # Create, train, test model\n",
    "# model = lgb.LGBMClassifier(**random_search_params, random_state = 42)\n",
    "# model.fit(train_features, train_labels)\n",
    "\n",
    "# preds = model.predict_proba(test_features)[:, 1]\n",
    "\n",
    "# print('The best model from random search scores {:.5f} ROC AUC on the test set.'.format(roc_auc_score(test_labels, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-cuisine",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:43:27.612501Z",
     "start_time": "2021-05-12T19:42:40.346Z"
    }
   },
   "outputs": [],
   "source": [
    "random_results['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-protest",
   "metadata": {},
   "source": [
    "### Stacking Random and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-mention",
   "metadata": {},
   "source": [
    "Keep the progress in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "formed-polish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:44:43.559327Z",
     "start_time": "2021-05-12T19:44:43.551298Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Create file and open connection\n",
    "out_file = 'random_search_trials.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write column names\n",
    "headers = ['score', 'hyperparameters', 'iteration']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-shaft",
   "metadata": {},
   "source": [
    "Modify `random_search` and `grid_search` to write to this file every time. We do this by opening a connection, this time using the \"a\" option for append (the first time we used the \"w\" option for write) and writing a line with the desired information (which in this case is the cross validation score, the hyperparameters, and the number of the iteration). Then we close the connection until the function is called again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "nominated-region",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:44:46.578347Z",
     "start_time": "2021-05-12T19:44:46.570348Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_search(param_grid, out_file, max_evals = MAX_EVALS):\n",
    "    \"\"\"Random search for hyperparameter optimization. \n",
    "       Writes result of search to csv file every search iteration.\"\"\"\n",
    "    \n",
    "    \n",
    "    # Dataframe for results\n",
    "    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                                  index = list(range(MAX_EVALS)))\n",
    "    for i in range(MAX_EVALS):\n",
    "        \n",
    "        # Choose random hyperparameters\n",
    "        random_params = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n",
    "        random_params['subsample'] = 1.0 if random_params['boosting_type'] == 'goss' else random_params['subsample']\n",
    "\n",
    "        # Evaluate randomly selected hyperparameters\n",
    "        eval_results = objective(random_params, i)\n",
    "        results.loc[i, :] = eval_results\n",
    "\n",
    "        # open connection (append option) and write results\n",
    "        of_connection = open(out_file, 'a')\n",
    "        writer = csv.writer(of_connection)\n",
    "        writer.writerow(eval_results)\n",
    "        \n",
    "        # make sure to close connection\n",
    "        of_connection.close()\n",
    "        \n",
    "    # Sort with best score on top\n",
    "    results.sort_values('score', ascending = False, inplace = True)\n",
    "    results.reset_index(inplace = True)\n",
    "\n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "increasing-intention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:44:47.136670Z",
     "start_time": "2021-05-12T19:44:47.116675Z"
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(param_grid, out_file, max_evals = MAX_EVALS):\n",
    "    \"\"\"Grid search algorithm (with limit on max evals)\n",
    "       Writes result of search to csv file every search iteration.\"\"\"\n",
    "    \n",
    "    # Dataframe to store results\n",
    "    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n",
    "                              index = list(range(MAX_EVALS)))\n",
    "    \n",
    "    # https://codereview.stackexchange.com/questions/171173/list-all-possible-permutations-from-a-python-dictionary-of-lists\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    # Iterate through every possible combination of hyperparameters\n",
    "    for v in itertools.product(*values):\n",
    "        # Select the hyperparameters\n",
    "        parameters = dict(zip(keys, v))\n",
    "        \n",
    "        # Set the subsample ratio accounting for boosting type\n",
    "        parameters['subsample'] = 1.0 if parameters['boosting_type'] == 'goss' else parameters['subsample']\n",
    "        \n",
    "        # Evalute the hyperparameters\n",
    "        eval_results = objective(parameters, i)\n",
    "        \n",
    "        results.loc[i, :] = eval_results\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        # open connection (append option) and write results\n",
    "        of_connection = open(out_file, 'a')\n",
    "        writer = csv.writer(of_connection)\n",
    "        writer.writerow(eval_results)\n",
    "        \n",
    "        # make sure to close connection\n",
    "        of_connection.close()\n",
    "        \n",
    "        # Normally would not limit iterations\n",
    "        if i > MAX_EVALS:\n",
    "            break\n",
    "       \n",
    "    # Sort with best score on top\n",
    "    results.sort_values('score', ascending = False, inplace = True)\n",
    "    results.reset_index(inplace = True)\n",
    "    \n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-hungarian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:43:27.616533Z",
     "start_time": "2021-05-12T19:42:40.384Z"
    }
   },
   "outputs": [],
   "source": [
    "# #This block of codes took 1h40mins to run in my machine\n",
    "# MAX_EVALS = 1000\n",
    "\n",
    "# # Create file and open connection\n",
    "# out_file = 'grid_search_trials_1000.csv'\n",
    "# of_connection = open(out_file, 'w')\n",
    "# writer = csv.writer(of_connection)\n",
    "\n",
    "# # Write column names\n",
    "# headers = ['score', 'hyperparameters', 'iteration']\n",
    "# writer.writerow(headers)\n",
    "# of_connection.close()\n",
    "\n",
    "# grid_results = grid_search(param_grid, out_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-surname",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:43:27.620530Z",
     "start_time": "2021-05-12T19:42:40.538Z"
    }
   },
   "outputs": [],
   "source": [
    "# #This block took 1h22min\n",
    "# # Create file and open connection\n",
    "# out_file = 'random_search_trials_1000.csv'\n",
    "# of_connection = open(out_file, 'w')\n",
    "# writer = csv.writer(of_connection)\n",
    "\n",
    "# # Write column names\n",
    "# headers = ['score', 'hyperparameters', 'iteration']\n",
    "# writer.writerow(headers)\n",
    "# of_connection.close()\n",
    "\n",
    "# random_results = random_search(param_grid, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-boring",
   "metadata": {},
   "source": [
    "### Results on Limited Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "maritime-breakfast",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:44:50.580372Z",
     "start_time": "2021-05-12T19:44:50.552400Z"
    }
   },
   "outputs": [],
   "source": [
    "random_results = pd.read_csv('random_search_trials_1000.csv')\n",
    "grid_results = pd.read_csv('grid_search_trials_1000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-morris",
   "metadata": {},
   "source": [
    "When we save the results to a csv, for some reason the dictionaries are saved as strings. Therefore we need to convert them back to dictionaries after reading in the results using the `ast.literal_eval` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fatty-chester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:45:18.349161Z",
     "start_time": "2021-05-12T19:45:18.228852Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Convert strings to dictionaries\n",
    "grid_results['hyperparameters'] = grid_results['hyperparameters'].map(ast.literal_eval)\n",
    "random_results['hyperparameters'] = random_results['hyperparameters'].map(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cooked-austin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:45:26.618626Z",
     "start_time": "2021-05-12T19:45:26.602625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.5, 'is_unbalance': True, 'n_estimators': 629}\n",
       "1                                    {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.5, 'is_unbalance': False, 'n_estimators': 629}\n",
       "2                      {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.5050505050505051, 'is_unbalance': True, 'n_estimators': 629}\n",
       "3                     {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.5050505050505051, 'is_unbalance': False, 'n_estimators': 629}\n",
       "4                        {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.6, 'subsample': 0.51010101010101, 'is_unbalance': True, 'n_estimators': 629}\n",
       "                                                                                                                                                      ...                                                                                                                                               \n",
       "996      {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.7777777777777778, 'subsample': 0.994949494949495, 'is_unbalance': True, 'n_estimators': 681}\n",
       "997     {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.7777777777777778, 'subsample': 0.994949494949495, 'is_unbalance': False, 'n_estimators': 681}\n",
       "998                    {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.7777777777777778, 'subsample': 1.0, 'is_unbalance': True, 'n_estimators': 681}\n",
       "999                   {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.7777777777777778, 'subsample': 1.0, 'is_unbalance': False, 'n_estimators': 681}\n",
       "1000                   {'boosting_type': 'gbdt', 'num_leaves': 20, 'learning_rate': 0.004999999999999999, 'subsample_for_bin': 20000, 'min_child_samples': 20, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'colsample_bytree': 0.8222222222222222, 'subsample': 0.5, 'is_unbalance': True, 'n_estimators': 755}\n",
       "Name: hyperparameters, Length: 1001, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "guilty-annotation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:45:34.389031Z",
     "start_time": "2021-05-12T19:45:34.377053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          {'n_estimators': 13, 'subsample_for_bin': 60000, 'learning_rate': 0.2849218529734569, 'num_leaves': 100, 'metric': 'auc', 'boosting_type': 'dart', 'verbose': 1, 'colsample_bytree': 0.8222222222222222, 'subsample': 0.5, 'reg_alpha': 0.836734693877551, 'min_child_samples': 485, 'is_unbalance': False, 'reg_lambda': 0.7755102040816326}\n",
       "1             {'n_estimators': 18, 'subsample_for_bin': 40000, 'learning_rate': 0.1881679181143267, 'num_leaves': 113, 'metric': 'auc', 'boosting_type': 'dart', 'verbose': 1, 'colsample_bytree': 0.7777777777777778, 'subsample': 0.98989898989899, 'reg_alpha': 0.8775510204081632, 'min_child_samples': 150, 'is_unbalance': True, 'reg_lambda': 0.3877551020408163}\n",
       "2      {'n_estimators': 514, 'subsample_for_bin': 180000, 'learning_rate': 0.009402520275642907, 'num_leaves': 29, 'metric': 'auc', 'boosting_type': 'gbdt', 'verbose': 1, 'colsample_bytree': 0.8222222222222222, 'subsample': 0.7575757575757576, 'reg_alpha': 0.22448979591836732, 'min_child_samples': 400, 'is_unbalance': False, 'reg_lambda': 0.7142857142857142}\n",
       "3      {'n_estimators': 236, 'subsample_for_bin': 100000, 'learning_rate': 0.015256485085914345, 'num_leaves': 126, 'metric': 'auc', 'boosting_type': 'gbdt', 'verbose': 1, 'colsample_bytree': 0.6888888888888889, 'subsample': 0.6262626262626263, 'reg_alpha': 0.7551020408163265, 'min_child_samples': 345, 'is_unbalance': True, 'reg_lambda': 0.14285714285714285}\n",
       "4                       {'n_estimators': 432, 'subsample_for_bin': 260000, 'learning_rate': 0.007032636210526181, 'num_leaves': 56, 'metric': 'auc', 'boosting_type': 'dart', 'verbose': 1, 'colsample_bytree': 1.0, 'subsample': 0.9343434343434344, 'reg_alpha': 0.04081632653061224, 'min_child_samples': 40, 'is_unbalance': True, 'reg_lambda': 0.8571428571428571}\n",
       "                                                                                                                                                                                     ...                                                                                                                                                                                \n",
       "995       {'n_estimators': 14, 'subsample_for_bin': 180000, 'learning_rate': 0.19887015120290172, 'num_leaves': 123, 'metric': 'auc', 'boosting_type': 'dart', 'verbose': 1, 'colsample_bytree': 0.7777777777777778, 'subsample': 0.7070707070707071, 'reg_alpha': 0.4693877551020408, 'min_child_samples': 115, 'is_unbalance': True, 'reg_lambda': 0.7142857142857142}\n",
       "996                                       {'n_estimators': 3, 'subsample_for_bin': 20000, 'learning_rate': 0.2160755563894882, 'num_leaves': 27, 'metric': 'auc', 'boosting_type': 'goss', 'verbose': 1, 'colsample_bytree': 1.0, 'subsample': 1.0, 'reg_alpha': 0.6326530612244897, 'min_child_samples': 395, 'is_unbalance': False, 'reg_lambda': 0.24489795918367346}\n",
       "997                      {'n_estimators': 36, 'subsample_for_bin': 200000, 'learning_rate': 0.026896807519903497, 'num_leaves': 65, 'metric': 'auc', 'boosting_type': 'goss', 'verbose': 1, 'colsample_bytree': 0.7333333333333333, 'subsample': 1.0, 'reg_alpha': 0.2857142857142857, 'min_child_samples': 480, 'is_unbalance': True, 'reg_lambda': 0.8163265306122448}\n",
       "998     {'n_estimators': 272, 'subsample_for_bin': 140000, 'learning_rate': 0.005662706575764057, 'num_leaves': 146, 'metric': 'auc', 'boosting_type': 'dart', 'verbose': 1, 'colsample_bytree': 0.8222222222222222, 'subsample': 0.5555555555555556, 'reg_alpha': 0.7346938775510203, 'min_child_samples': 55, 'is_unbalance': False, 'reg_lambda': 0.1020408163265306}\n",
       "999                        {'n_estimators': 6, 'subsample_for_bin': 220000, 'learning_rate': 0.1543332471668636, 'num_leaves': 76, 'metric': 'auc', 'boosting_type': 'goss', 'verbose': 1, 'colsample_bytree': 0.8222222222222222, 'subsample': 1.0, 'reg_alpha': 0.22448979591836732, 'min_child_samples': 460, 'is_unbalance': True, 'reg_lambda': 0.9795918367346939}\n",
       "Name: hyperparameters, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_results['hyperparameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-contest",
   "metadata": {},
   "source": [
    "Now let's make a function to parse the results from the hyperparameter searches. This returns a dataframe where each column is a hyperparameter and each row has one search result (so taking the dictionary of hyperparameters and mapping it into a row in a dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "behavioral-filling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:46:16.398773Z",
     "start_time": "2021-05-12T19:46:16.390773Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(results, name):\n",
    "    \"\"\"Evaluate model on test data using hyperparameters in results\n",
    "       Return dataframe of hyperparameters\"\"\"\n",
    "        \n",
    "    # Sort with best values on top\n",
    "    results = results.sort_values('score', ascending = False).reset_index(drop = True)\n",
    "    \n",
    "    # Print out cross validation high score\n",
    "    print('The highest cross validation score from {} was {:.5f} found on iteration {}.'.format(name, results.loc[0, 'score'], results.loc[0, 'iteration']))\n",
    "    \n",
    "    # Use best hyperparameters to create a model\n",
    "    hyperparameters = results.loc[0, 'hyperparameters']\n",
    "    model = lgb.LGBMClassifier(**hyperparameters)\n",
    "    \n",
    "    # Train and make predictions\n",
    "    model.fit(train_features, train_labels)\n",
    "    preds = model.predict_proba(test_features)[:, 1]\n",
    "    \n",
    "    print('ROC AUC from {} on test data = {:.5f}.'.format(name, roc_auc_score(test_labels, preds)))\n",
    "    \n",
    "    # Create dataframe of hyperparameters\n",
    "    hyp_df = pd.DataFrame(columns = list(results.loc[0, 'hyperparameters'].keys()))\n",
    "\n",
    "    # Iterate through each set of hyperparameters that were evaluated\n",
    "    for i, hyp in enumerate(results['hyperparameters']):\n",
    "        hyp_df = hyp_df.append(pd.DataFrame(hyp, index = [0]), \n",
    "                               ignore_index = True)\n",
    "        \n",
    "    # Put the iteration and score in the hyperparameter dataframe\n",
    "    hyp_df['iteration'] = results['iteration']\n",
    "    hyp_df['score'] = results['score']\n",
    "    \n",
    "    return hyp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "novel-illness",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:46:29.487506Z",
     "start_time": "2021-05-12T19:46:25.951340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest cross validation score from grid search was 0.72024 found on iteration 0.\n",
      "ROC AUC from grid search on test data = 0.73471.\n"
     ]
    }
   ],
   "source": [
    "grid_hyp = evaluate(grid_results, name = 'grid search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "perfect-ferry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:46:45.501759Z",
     "start_time": "2021-05-12T19:46:42.249575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest cross validation score from random search was 0.73448 found on iteration 596.\n",
      "[LightGBM] [Info] Number of positive: 817, number of negative: 9183\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9975\n",
      "[LightGBM] [Info] Number of data points in the train set: 10000, number of used features: 84\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081700 -> initscore=-2.419470\n",
      "[LightGBM] [Info] Start training from score -2.419470\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "ROC AUC from random search on test data = 0.73505.\n"
     ]
    }
   ],
   "source": [
    "random_hyp = evaluate(random_results, name = 'random search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "emotional-arrangement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:48:48.250941Z",
     "start_time": "2021-05-12T19:48:48.238940Z"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters = dict(**random_results.loc[0, 'hyperparameters'])\n",
    "del hyperparameters['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "electoral-baptist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:48:51.849967Z",
     "start_time": "2021-05-12T19:48:51.833942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample_for_bin': 60000,\n",
       " 'learning_rate': 0.2849218529734569,\n",
       " 'num_leaves': 100,\n",
       " 'metric': 'auc',\n",
       " 'boosting_type': 'dart',\n",
       " 'verbose': 1,\n",
       " 'colsample_bytree': 0.8222222222222222,\n",
       " 'subsample': 0.5,\n",
       " 'reg_alpha': 0.836734693877551,\n",
       " 'min_child_samples': 485,\n",
       " 'is_unbalance': False,\n",
       " 'reg_lambda': 0.7755102040816326}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-delay",
   "metadata": {},
   "source": [
    "### Train on full dataset with the `hyperparameters` we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "banned-insertion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:50:46.294628Z",
     "start_time": "2021-05-12T19:50:42.866630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 247)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Block</th>\n",
       "      <th>WALLSMATERIAL_MODE_Mixed</th>\n",
       "      <th>WALLSMATERIAL_MODE_Monolithic</th>\n",
       "      <th>WALLSMATERIAL_MODE_Others</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>DAYS_EMPLOYED_ANOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>637.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005</td>\n",
       "      <td>3039.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0      100002       1             0          202500.0    406597.5   \n",
       "1      100003       0             0          270000.0   1293502.5   \n",
       "2      100004       0             0           67500.0    135000.0   \n",
       "3      100006       0             0          135000.0    312682.5   \n",
       "4      100007       0             0          121500.0    513000.0   \n",
       "\n",
       "   AMT_ANNUITY  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "0      24700.5         351000.0                    0.018801       -9461   \n",
       "1      35698.5        1129500.0                    0.003541      -16765   \n",
       "2       6750.0         135000.0                    0.010032      -19046   \n",
       "3      29686.5         297000.0                    0.008019      -19005   \n",
       "4      21865.5         513000.0                    0.028663      -19932   \n",
       "\n",
       "   DAYS_EMPLOYED  ...  WALLSMATERIAL_MODE_Block  WALLSMATERIAL_MODE_Mixed  \\\n",
       "0          637.0  ...                         0                         0   \n",
       "1         1188.0  ...                         1                         0   \n",
       "2          225.0  ...                         0                         0   \n",
       "3         3039.0  ...                         0                         0   \n",
       "4         3038.0  ...                         0                         0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Monolithic  WALLSMATERIAL_MODE_Others  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "0                         0                                1   \n",
       "1                         0                                0   \n",
       "2                         0                                0   \n",
       "3                         0                                0   \n",
       "4                         0                                0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Wooden  EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  \\\n",
       "0                          0                       1                        0   \n",
       "1                          0                       1                        0   \n",
       "2                          0                       0                        0   \n",
       "3                          0                       0                        0   \n",
       "4                          0                       0                        0   \n",
       "\n",
       "   DAYS_EMPLOYED_ANOM  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "\n",
       "[5 rows x 247 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train = pd.read_csv('app_train.csv', index_col=0)\n",
    "print(app_train.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "modular-yukon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:51:30.236435Z",
     "start_time": "2021-05-12T19:51:30.180420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 251)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>DAYS_EMPLOYED_ANOM</th>\n",
       "      <th>CREDIT_INCOME_PERCENT</th>\n",
       "      <th>ANNUITY_INCOME_PERCENT</th>\n",
       "      <th>CREDIT_TERM</th>\n",
       "      <th>DAYS_EMPLOYED_PERCENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>637.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.007889</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>-0.067329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.790750</td>\n",
       "      <td>0.132217</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>-0.070862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.011814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005</td>\n",
       "      <td>3039.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.316167</td>\n",
       "      <td>0.219900</td>\n",
       "      <td>0.094941</td>\n",
       "      <td>-0.159905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>3038.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>0.179963</td>\n",
       "      <td>0.042623</td>\n",
       "      <td>-0.152418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "0      100002       1             0          202500.0    406597.5   \n",
       "1      100003       0             0          270000.0   1293502.5   \n",
       "2      100004       0             0           67500.0    135000.0   \n",
       "3      100006       0             0          135000.0    312682.5   \n",
       "4      100007       0             0          121500.0    513000.0   \n",
       "\n",
       "   AMT_ANNUITY  AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "0      24700.5         351000.0                    0.018801       -9461   \n",
       "1      35698.5        1129500.0                    0.003541      -16765   \n",
       "2       6750.0         135000.0                    0.010032      -19046   \n",
       "3      29686.5         297000.0                    0.008019      -19005   \n",
       "4      21865.5         513000.0                    0.028663      -19932   \n",
       "\n",
       "   DAYS_EMPLOYED  ...  WALLSMATERIAL_MODE_Panel  \\\n",
       "0          637.0  ...                         0   \n",
       "1         1188.0  ...                         0   \n",
       "2          225.0  ...                         0   \n",
       "3         3039.0  ...                         0   \n",
       "4         3038.0  ...                         0   \n",
       "\n",
       "   WALLSMATERIAL_MODE_Stone, brick  WALLSMATERIAL_MODE_Wooden  \\\n",
       "0                                1                          0   \n",
       "1                                0                          0   \n",
       "2                                0                          0   \n",
       "3                                0                          0   \n",
       "4                                0                          0   \n",
       "\n",
       "   EMERGENCYSTATE_MODE_No  EMERGENCYSTATE_MODE_Yes  DAYS_EMPLOYED_ANOM  \\\n",
       "0                       1                        0               False   \n",
       "1                       1                        0               False   \n",
       "2                       0                        0               False   \n",
       "3                       0                        0               False   \n",
       "4                       0                        0               False   \n",
       "\n",
       "   CREDIT_INCOME_PERCENT  ANNUITY_INCOME_PERCENT  CREDIT_TERM  \\\n",
       "0               2.007889                0.121978     0.060749   \n",
       "1               4.790750                0.132217     0.027598   \n",
       "2               2.000000                0.100000     0.050000   \n",
       "3               2.316167                0.219900     0.094941   \n",
       "4               4.222222                0.179963     0.042623   \n",
       "\n",
       "   DAYS_EMPLOYED_PERCENT  \n",
       "0              -0.067329  \n",
       "1              -0.070862  \n",
       "2              -0.011814  \n",
       "3              -0.159905  \n",
       "4              -0.152418  \n",
       "\n",
       "[5 rows x 251 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train['CREDIT_INCOME_PERCENT'] = app_train['AMT_CREDIT'] / app_train['AMT_INCOME_TOTAL']\n",
    "app_train['ANNUITY_INCOME_PERCENT'] = app_train['AMT_ANNUITY'] / app_train['AMT_INCOME_TOTAL']\n",
    "app_train['CREDIT_TERM'] = app_train['AMT_ANNUITY'] / app_train['AMT_CREDIT']\n",
    "app_train['DAYS_EMPLOYED_PERCENT'] = app_train['DAYS_EMPLOYED'] / app_train['DAYS_BIRTH']\n",
    "print(app_train.shape)\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dense-confusion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:51:38.528980Z",
     "start_time": "2021-05-12T19:51:37.760953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (246008, 250)\n",
      "X_test shape:  (61503, 250)\n",
      "y_train shape:  (246008,)\n",
      "y_test shape:  (61503,)\n"
     ]
    }
   ],
   "source": [
    "X = app_train.drop(columns=['TARGET'])\n",
    "y = app_train.TARGET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "applied-prize",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T19:54:26.811499Z",
     "start_time": "2021-05-12T19:54:13.347724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (246008, 250)\n",
      "X_test shape:  (61503, 250)\n"
     ]
    }
   ],
   "source": [
    "X_train_lr = X_train.copy()\n",
    "X_test_lr = X_test.copy()\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#features columns\n",
    "features = list(X_train.columns)\n",
    "\n",
    "#test set\n",
    "\n",
    "#SimpleImputer wirth strategy = median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "#Scale the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit on the training data\n",
    "\n",
    "#Imputer\n",
    "imputer.fit(X_train_lr)\n",
    "X_train_lr = imputer.transform(X_train_lr)\n",
    "X_test_lr = imputer.transform(X_test_lr)\n",
    "\n",
    "#Scaler\n",
    "scaler.fit(X_train_lr)\n",
    "X_train_lr = scaler.transform(X_train_lr)\n",
    "X_test_lr = scaler.transform(X_test_lr)\n",
    "\n",
    "print('X_train shape: ', X_train_lr.shape)\n",
    "print('X_test shape: ', X_test_lr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "prospective-harvest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T20:02:27.846397Z",
     "start_time": "2021-05-12T20:02:27.834395Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_lgb = np.array(y_train.astype(np.int32)).reshape((-1, ))\n",
    "y_test_lgb = np.array(y_test.astype(np.int32)).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "designed-ethernet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T20:06:25.881498Z",
     "start_time": "2021-05-12T20:06:25.867536Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set_lgb = lgb.Dataset(data=X_train, label=y_train_lgb, free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "subjective-softball",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T20:08:29.660213Z",
     "start_time": "2021-05-12T20:08:29.642250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lightgbm.basic.Dataset"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "rising-census",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T20:07:03.266746Z",
     "start_time": "2021-05-12T20:07:03.248763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample_for_bin': 60000,\n",
       " 'learning_rate': 0.2849218529734569,\n",
       " 'num_leaves': 100,\n",
       " 'metric': 'auc',\n",
       " 'boosting_type': 'dart',\n",
       " 'verbose': 1,\n",
       " 'colsample_bytree': 0.8222222222222222,\n",
       " 'subsample': 0.5,\n",
       " 'reg_alpha': 0.836734693877551,\n",
       " 'min_child_samples': 485,\n",
       " 'is_unbalance': False,\n",
       " 'reg_lambda': 0.7755102040816326}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "viral-zimbabwe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T20:25:47.133616Z",
     "start_time": "2021-05-12T20:24:45.538006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12271\n",
      "[LightGBM] [Info] Number of data points in the train set: 196806, number of used features: 207\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12271\n",
      "[LightGBM] [Info] Number of data points in the train set: 196806, number of used features: 207\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12271\n",
      "[LightGBM] [Info] Number of data points in the train set: 196806, number of used features: 207\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12271\n",
      "[LightGBM] [Info] Number of data points in the train set: 196807, number of used features: 207\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12271\n",
      "[LightGBM] [Info] Number of data points in the train set: 196807, number of used features: 207\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.080795\n",
      "[LightGBM] [Info] Start training from score 0.080795\n",
      "[LightGBM] [Info] Start training from score 0.080790\n",
      "[LightGBM] [Info] Start training from score 0.080795\n",
      "[LightGBM] [Info] Start training from score 0.080795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tqluo\\Anaconda3\\envs\\metis\\lib\\site-packages\\lightgbm\\callback.py:183: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    }
   ],
   "source": [
    "#Cross val with early stopping\n",
    "cv_results = lgb.cv(hyperparameters, train_set=train_set_lgb, \n",
    "                    num_boost_round=200, early_stopping_rounds=10, metrics='auc', nfold = N_FOLDS, seed=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bizarre-suffering",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T20:27:05.725337Z",
     "start_time": "2021-05-12T20:27:05.718385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation score on the full dataset = 0.74812 with std: 0.00254.\n",
      "Number of estimators = 200.\n"
     ]
    }
   ],
   "source": [
    "print('The cross validation score on the full dataset = {:.5f} with std: {:.5f}.'.format(\n",
    "    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\n",
    "print('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "homeless-lighter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T20:30:01.787186Z",
     "start_time": "2021-05-12T20:30:01.774209Z"
    }
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), **hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "behavioral-payday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T21:02:36.054964Z",
     "start_time": "2021-05-12T21:02:15.176498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19876, number of negative: 226132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12271\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 207\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080794 -> initscore=-2.431606\n",
      "[LightGBM] [Info] Start training from score -2.431606\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', colsample_bytree=0.8222222222222222,\n",
       "               is_unbalance=False, learning_rate=0.2849218529734569,\n",
       "               metric='auc', min_child_samples=485, n_estimators=200,\n",
       "               num_leaves=100, reg_alpha=0.836734693877551,\n",
       "               reg_lambda=0.7755102040816326, subsample=0.5,\n",
       "               subsample_for_bin=60000, verbose=1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "X_train = X_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "model.fit(X_train, y_train_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "parallel-feeding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T21:03:23.842616Z",
     "start_time": "2021-05-12T21:03:22.787441Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fresh-economy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T21:03:37.974392Z",
     "start_time": "2021-05-12T21:03:36.912165Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_hard = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "organic-matrix",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T21:06:56.240258Z",
     "start_time": "2021-05-12T21:06:56.191387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7599108566250459\n",
      "0.059519267455169785\n"
     ]
    }
   ],
   "source": [
    "#Test sets\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, precision_score, recall_score, fbeta_score\n",
    "print(roc_auc_score(y_test, preds))\n",
    "print(f1_score(y_test, preds_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "promotional-pursuit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T21:06:35.096563Z",
     "start_time": "2021-05-12T21:06:35.046726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5324232081911263\n",
      "0.031521519498888664\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, preds_hard))\n",
    "print(recall_score(y_test, preds_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "close-examination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T21:07:37.377258Z",
     "start_time": "2021-05-12T21:07:37.342351Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tqluo\\Anaconda3\\envs\\metis\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass beta=0.5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1274301584708381"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, preds_hard, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-doctor",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-alliance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "199.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
